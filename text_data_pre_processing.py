# -*- coding: utf-8 -*-
"""Text data Pre-Processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12App_1j6paFRFoiBxFtetnfrx8XmqMJy
"""

import numpy as np
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split

nltk.download('stopwords')
print(stopwords.words('english'))

news_data_df = pd.read_csv('/content/fake_news_dataset.csv')

news_data_df.head()

news_data_df.shape

news_data_df.isnull().sum()

news_data_df = news_data_df.fillna('')

news_data_df['content'] = news_data_df['author']+' '+news_data_df['title']

news_data_df.head()

X = news_data_df.drop(columns='label', axis=1)
Y = news_data_df['label']

print(X)

print(Y)

port_stem = PorterStemmer()

def steming(content):
  stemmed_content = re.sub('[^a-zA-Z]',' ',content)
  stemmed_content = stemmed_content.lower()
  stemmed_content = stemmed_content.split()
  stemmed_content =[port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]
  stemmed_content = ' '.join(stemmed_content)
  return stemmed_content

news_data_df['content'] = news_data_df['content'].apply(steming)

print(news_data_df['content'])

X=news_data_df['content'].values
Y=news_data_df['label'].values

Y.shape

vectorizer = TfidfVectorizer()
vectorizer.fit(X)
X=vectorizer.transform(X)

print(X)